{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.082028Z",
     "start_time": "2024-02-16T14:06:17.364513Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Préparation du dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "983e9b72dcd5caff"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                           critiques  labels\n0  Didn't meet the expectations with the predicta...       0\n1  Struggled to get through the underwhelming vis...       0\n2  Didn't meet the expectations with the dull plo...       0\n3  Absolutely loved the brilliant storyline. A mu...       1\n4  Was blown away by the exceptional directing. W...       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>critiques</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Didn't meet the expectations with the predicta...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Struggled to get through the underwhelming vis...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Didn't meet the expectations with the dull plo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Absolutely loved the brilliant storyline. A mu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Was blown away by the exceptional directing. W...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_dataset = pd.read_csv('reviews_unique.csv')\n",
    "reviews_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.088896Z",
     "start_time": "2024-02-16T14:06:19.082823Z"
    }
   },
   "id": "524e9af69b45b212",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124 entries, 0 to 123\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   critiques  124 non-null    object\n",
      " 1   labels     124 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.094217Z",
     "start_time": "2024-02-16T14:06:19.091771Z"
    }
   },
   "id": "b8a6490446cdf6f6",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   critiques  85 non-null     object\n",
      " 1   labels     85 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "reviews_dataset.drop_duplicates(subset=['critiques'], inplace=True)\n",
    "reviews_dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.100955Z",
     "start_time": "2024-02-16T14:06:19.097839Z"
    }
   },
   "id": "73a6e9b7049c2e79",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "**On est passé de 124 à 85 critiques uniques**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b0956649b1a19f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "critiques = reviews_dataset['critiques']\n",
    "rateValue = reviews_dataset['labels']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.103651Z",
     "start_time": "2024-02-16T14:06:19.100320Z"
    }
   },
   "id": "d48b7d7ae5a9f3e0",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        17\n",
      "   macro avg       1.00      1.00      1.00        17\n",
      "weighted avg       1.00      1.00      1.00        17\n",
      "\n",
      "AUC-ROC: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "['movie_review_classifier.joblib']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(rateValue)\n",
    "\n",
    "# Vectorisation du texte\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(critiques)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# On choisit un modèle de régression logistique\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation de la performance du modèle\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"AUC-ROC:\", roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Sauvegarde du modèle entraîné\n",
    "filename = './movie_review_classifier.joblib'\n",
    "joblib.dump(model, filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T14:06:19.140967Z",
     "start_time": "2024-02-16T14:06:19.106253Z"
    }
   },
   "id": "1494914893ca0cb3",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le modèle a une performance de 1.00 pour la prédiction des critiques positives (1) et 1.00 pour les critiques négatives (0). Idem pour l'AUC-ROC. ce qui signifie que le modèle prédit parfaitement les sorties (un poil trop beau pour être vrai)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4a4574134986310"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
